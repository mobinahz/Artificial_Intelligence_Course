{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ],
      "metadata": {
        "id": "eY99YE-VG1C9"
      },
      "id": "eY99YE-VG1C9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec65989e04597f0",
      "metadata": {
        "id": "fec65989e04597f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d019598-09fb-472b-d1e0-8df84cef855e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/433.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/433.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gensim emoji nltk tqdm seaborn torch torchsummary -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import gensim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import os\n",
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf946d026ed2d98e",
      "metadata": {
        "collapsed": false,
        "id": "cf946d026ed2d98e"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e83a8b72b644c2",
      "metadata": {
        "collapsed": false,
        "id": "3e83a8b72b644c2"
      },
      "source": [
        "## Model training config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0826c5b8eb52c9",
      "metadata": {
        "id": "2d0826c5b8eb52c9"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 4e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 15\n",
        "\n",
        "SEQUENCE_LEN = 64\n",
        "CNN_FILTERS = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f939dd5898a0b6",
      "metadata": {
        "id": "b1f939dd5898a0b6"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27110752c038c1d0",
      "metadata": {
        "collapsed": false,
        "id": "27110752c038c1d0"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b050729991fec9",
      "metadata": {
        "collapsed": false,
        "id": "32b050729991fec9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e92f34d72c6f62",
      "metadata": {
        "id": "88e92f34d72c6f62"
      },
      "outputs": [],
      "source": [
        "# TODO: Load read and load the data here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f7552c58ea498e",
      "metadata": {
        "collapsed": false,
        "id": "57f7552c58ea498e"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f16efd0184e90f40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f16efd0184e90f40",
        "outputId": "44e62e18-a7ba-4ce1-8bf6-0ec77ca51205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import nltk\n",
        "import emoji\n",
        "import re\n",
        "\n",
        "nltk.download([\"stopwords\", \"punkt\", \"wordnet\", \"averaged_perceptron_tagger\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe50f445aa09ecc",
      "metadata": {
        "id": "dbe50f445aa09ecc"
      },
      "outputs": [],
      "source": [
        "def convert_emoji_to_text(text):\n",
        "    \"\"\"This function would replace emojies with a space\"\"\"\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def nltk_pos_tagger(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return 'a'\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return 'v'\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return 'n'\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return 'r'\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "def preprocess_data(text: str):\n",
        "    \"\"\"\n",
        "    Preprocessing steps are as follows:\n",
        "    1. lowercase the text\n",
        "    2. remove punctuation\n",
        "    3. remove numbers\n",
        "    4. remove urls\n",
        "    5. remove usernames\n",
        "    6. remove extra spaces\n",
        "    7. convert emojis to text\n",
        "    8. remove non-word characters\n",
        "    9. lemmatization and tokenization of the text\n",
        "    10. remove stopwords\n",
        "    :param text: str\n",
        "    :return: tokens: list[str]\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: lowercase the text\n",
        "\n",
        "    # TODO: remove punctuation\n",
        "\n",
        "    # TODO: remove numbers\n",
        "\n",
        "    # TODO: remove urls,\n",
        "\n",
        "    # TODO: remove usernames\n",
        "\n",
        "    # TODO: remove extra spaces\n",
        "\n",
        "    # TODO: convert emojis to text\n",
        "\n",
        "    # TODO: remove non-word characters\n",
        "\n",
        "    # TODO: lemmatization and tokenization of the text\n",
        "\n",
        "    # TODO: remove stopwords\n",
        "\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ac7d394e03d9f",
      "metadata": {
        "id": "11ac7d394e03d9f"
      },
      "outputs": [],
      "source": [
        "## TODO: Show some samples before/after preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e129c7a31663741",
      "metadata": {
        "collapsed": false,
        "id": "2e129c7a31663741"
      },
      "source": [
        "# Word2Vec - Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d15b31459fd1e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d15b31459fd1e5",
        "outputId": "76a14c70-c496-4f53-b1f1-9f7626a0f9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fasttext-wiki-news-subwords-300\n",
            "conceptnet-numberbatch-17-06-300\n",
            "word2vec-ruscorpora-300\n",
            "word2vec-google-news-300\n",
            "glove-wiki-gigaword-50\n",
            "glove-wiki-gigaword-100\n",
            "glove-wiki-gigaword-200\n",
            "glove-wiki-gigaword-300\n",
            "glove-twitter-25\n",
            "glove-twitter-50\n",
            "glove-twitter-100\n",
            "glove-twitter-200\n",
            "__testing_word2vec-matrix-synopsis\n"
          ]
        }
      ],
      "source": [
        "# print available word2vec models\n",
        "import gensim.downloader as api\n",
        "print(\"\\n\".join(api.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55bbe6faa1226b8d",
      "metadata": {
        "id": "55bbe6faa1226b8d"
      },
      "outputs": [],
      "source": [
        "W2V_PATH = None # Path to W2V if downloaded\n",
        "if W2V_PATH is not None and os.path.exists(W2V_PATH):\n",
        "    print(\"Loading Word2Vec model...\")\n",
        "    w2v_model = gensim.models.KeyedVectors.load(W2V_PATH, mmap='r')\n",
        "    print(\"Word2Vec model is loaded.\")\n",
        "else:\n",
        "    print(\"Downloading Word2Vec model...\")\n",
        "    w2v_model = api.load(\"word2vec-google-news-300\")\n",
        "    print(\"Word2vec model is downloaded.\")\n",
        "    if W2V_PATH is not None:\n",
        "      print(\"\\nSaving Word2Vec model...\")\n",
        "      w2v_model.save(W2V_PATH)\n",
        "      print(\"Word2Vec model is saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d53926889defc38",
      "metadata": {
        "id": "7d53926889defc38"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_VECTOR_DIM = w2v_model.vector_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21730f8dd01e5b4e",
      "metadata": {
        "collapsed": false,
        "id": "21730f8dd01e5b4e"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xdqLYrA4xjuX",
      "metadata": {
        "id": "xdqLYrA4xjuX"
      },
      "outputs": [],
      "source": [
        "class Twitter(Dataset):\n",
        "    def __init__(self, dataframe: pd.DataFrame, w2v_model: gensim.models.KeyedVectors, sequence_len: int):\n",
        "        self.dataframe = dataframe\n",
        "        self.w2v_model = w2v_model\n",
        "        self.max_sequence_len = sequence_len\n",
        "        self.vector_size = w2v_model.vector_size\n",
        "\n",
        "        self.df_token_col = \"tokens\"\n",
        "\n",
        "\n",
        "        self._proc_dataset()\n",
        "\n",
        "        self.len = len(self.dataframe)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataframe.iloc[idx][\"vector\"], self.dataframe.iloc[idx][\"intention\"]\n",
        "\n",
        "    def get_vector_size(self):\n",
        "        return self.vector_size\n",
        "\n",
        "    def _proc_dataset(self):\n",
        "        # Preprocess and return tokens list\n",
        "        self.dataframe[self.df_token_col] = self.dataframe[\"tweet\"].map(preprocess_data)\n",
        "\n",
        "        # delete samples with empty tokens\n",
        "        lwz = len(self.dataframe)\n",
        "        self.dataframe = self.dataframe[self.dataframe[self.df_token_col].map(len) > 0]\n",
        "        self.dataframe.reset_index(drop=True, inplace=True)\n",
        "        print(f\"Deleted 0-Len Samples: {lwz - len(self.dataframe)}\")\n",
        "\n",
        "        # Add padding\n",
        "        self.dataframe[self.df_token_col] = self.dataframe[self.df_token_col].map(self._pad)\n",
        "\n",
        "        # Get embedding's vectors\n",
        "        self.dataframe[\"vector\"] = self.dataframe[self.df_token_col].map(self._get_word_vectors)\n",
        "\n",
        "    def _get_word_vectors(self, tokens: list) -> torch.tensor:\n",
        "      # TODO: Return a 2D tensor for whole list of tokens, using vectors from w2v as explained on the description\n",
        "\n",
        "\n",
        "    def _pad(self, tokens: list):\n",
        "        # TODO: Add paddings (zero-vectors) into the end of sequence to reach the desired length\n",
        "\n",
        "    def seq_report(self):\n",
        "        length_all = self.dataframe[self.df_token_col].map(len).tolist()\n",
        "        max_length = np.max(length_all)\n",
        "        print(f\"Sequence Length Report\")\n",
        "        print(f\":::::MAX  LENGTH:::[{max_length:^5}]\")\n",
        "        print(f\":::::MIN  LENGTH:::[{np.min(length_all):^5}]\")\n",
        "        print(f\":::::MEAN LENGTH:::[{np.mean(length_all):^5}]\")\n",
        "\n",
        "        all_tokens = set()\n",
        "        for token_set in self.dataframe[self.df_token_col].tolist():\n",
        "            all_tokens = all_tokens.union(set(token_set))\n",
        "        unique_tokens_count = len(all_tokens)\n",
        "        valid_tokens = sum(1 if token in self.w2v_model else 0 for token in all_tokens)\n",
        "        print(\"Sequence Tokenization Report\")\n",
        "        print(f\":::::All Unique Tokens:::[{unique_tokens_count:^6}\")\n",
        "        print(f\":::::All Valid Tokens:::[{valid_tokens:^6}\")\n",
        "        print(f\":::::Valid Tokens:::[{round(100*valid_tokens/unique_tokens_count, 2):^5}%]\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_tensor(tokens: list):\n",
        "        return torch.tensor(tokens, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b87e7e8b267a1c8",
      "metadata": {
        "collapsed": false,
        "id": "4b87e7e8b267a1c8"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd00ab880892e646",
      "metadata": {
        "collapsed": false,
        "id": "bd00ab880892e646"
      },
      "source": [
        "## Split Data into train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a54facda2729872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a54facda2729872",
        "outputId": "970c41d9-1af0-4892-c42d-2fee01e1a0ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# TODO: Split dataset into train-test split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "670fcd8db0e5651c",
      "metadata": {
        "collapsed": false,
        "id": "670fcd8db0e5651c"
      },
      "source": [
        "## Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4a5b690afadad5",
      "metadata": {
        "id": "3e4a5b690afadad5"
      },
      "outputs": [],
      "source": [
        "# TODO: create twitter dataset\n",
        "train_dataset = Twitter(\n",
        "    ...\n",
        ")\n",
        "valid_dataset = Twitter(\n",
        "    ...\n",
        ")\n",
        "\n",
        "print(f\"Train dataset length: {len(train_dataset)}\")\n",
        "print(f\"Valid dataset length: {len(valid_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd1da733e79676ff",
      "metadata": {
        "collapsed": false,
        "id": "fd1da733e79676ff"
      },
      "source": [
        "# Model and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa29012e257e3d9",
      "metadata": {
        "collapsed": false,
        "id": "aa29012e257e3d9"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b33657ae501516",
      "metadata": {
        "id": "d5b33657ae501516"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def model_eval(model, loader, loss_function, device: str['cuda', 'cpu', 'auto']):\n",
        "    \"\"\"Returns test_loss, test_acc\"\"\"\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "\n",
        "    if device == \"auto\":\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    itr = tqdm(loader, total=len(loader), leave=False)\n",
        "\n",
        "    for inputs, labels in itr:\n",
        "        # TODO: move model's inputs to `device`\n",
        "\n",
        "        # TODO: use model's forward pass to generate outputs\n",
        "\n",
        "        # TODO: calculate model's loss\n",
        "        # loss =\n",
        "\n",
        "        # TODO: calculate/update model's accuracy\n",
        "\n",
        "        itr.set_description(\"(Eval)\")\n",
        "        itr.set_postfix(\n",
        "            loss=round(loss.item(), 5),\n",
        "            accuracy=round(test_acc, 5),\n",
        "        )\n",
        "\n",
        "    return test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc1edee98f616b5",
      "metadata": {
        "id": "1bc1edee98f616b5"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "        model,\n",
        "        batch_size,\n",
        "        loss_function,\n",
        "        optimizer,\n",
        "        epochs,\n",
        "        train_set,\n",
        "        valid_set,\n",
        "        device: str['cuda', 'cpu', 'auto'],\n",
        "):\n",
        "\n",
        "    if device == \"auto\":\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "\n",
        "    valid_losses = []\n",
        "    valid_accs = []\n",
        "\n",
        "    # TODO: create dataloaders from datasets\n",
        "    # train_loader =\n",
        "    # valid_loader =\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    itr = tqdm(train_loader, total=len(train_loader), leave=False)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        for idx, (inputs, labels) in enumerate(itr, start=1):\n",
        "            # TODO: move model's inputs to `device`\n",
        "\n",
        "            # TODO: use model's forward pass to generate outputs\n",
        "\n",
        "            # TODO: process model's predictipns and calculate/update accuracy\n",
        "\n",
        "            # TODO: calculate model's loss and update epoch's loss\n",
        "            # loss =\n",
        "\n",
        "            # TODO: 1. clear optimizer's state and zero prev grads,\n",
        "            # TODO: 2. backward calculated loss\n",
        "            # TODO: 3. step optimizer\n",
        "\n",
        "            itr.set_description(f\"(Training) Epoch [{epoch + 1}/{epochs}]\")\n",
        "            itr.set_postfix(\n",
        "              loss=round(loss.item(), 5),\n",
        "              accuracy=round(epoch_acc, 5),\n",
        "              )\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss, valid_acc = model_eval(\n",
        "            model=model,\n",
        "            loader=valid_loader,\n",
        "            loss_function=loss_function,\n",
        "            device=device\n",
        "            )\n",
        "\n",
        "        # TODO: update statistics regaurding model's loss and acc in training or validation phases\n",
        "\n",
        "    history = {\n",
        "      \"train_loss\": train_losses,\n",
        "      \"train_acc\": train_accs,\n",
        "\n",
        "      \"valid_loss\": valid_losses,\n",
        "      \"valid_acc\": valid_accs,\n",
        "    }\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5acc20a7d5d446",
      "metadata": {
        "id": "6e5acc20a7d5d446"
      },
      "outputs": [],
      "source": [
        "def trend_plot_helper(pobj):\n",
        "    plt.figure(figsize=(5*len(pobj), 5))\n",
        "    for idx, (titler, plots) in enumerate(pobj.items(), start=1):\n",
        "        plt.subplot(1, len(pobj), idx)\n",
        "        for label, trend in plots:\n",
        "            plt.plot(range(1, len(trend)+1), trend, label=label)\n",
        "        yt, xt = titler.split(' - ')\n",
        "        plt.xlabel(xt)\n",
        "        plt.ylabel(yt)\n",
        "        plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819f88c36492de48",
      "metadata": {
        "id": "819f88c36492de48"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate_confusion_matrix(model, dataset, device='auto'):\n",
        "    if device == 'auto':\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "    itr = tqdm(loader, leave=False, desc=\"Generate data\")\n",
        "\n",
        "    # TODO: code here, you must fill variables below\n",
        "    # TODO: labels = true labels from the dataset\n",
        "    # TODO: predicted = labels predicted by the model\n",
        "\n",
        "    cm = metrics.confusion_matrix(\n",
        "        y_true=labels,\n",
        "        y_pred=predicted,\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    sns.heatmap(cm, cmap='Blues', annot=True, cbar=False, fmt=\".0f\",)\n",
        "    plt.xlabel('Predicted Label', labelpad=20)\n",
        "    plt.ylabel('True Label', labelpad=20)\n",
        "    plt.title('Confusion Matrix', fontsize=30)\n",
        "\n",
        "    recall = metrics.recall_score(y_true=labels, y_pred=predicted, average='macro')\n",
        "    f1 = metrics.f1_score(y_true=labels, y_pred=predicted, average='macro')\n",
        "    precision = metrics.precision_score(y_true=labels, y_pred=predicted, average='macro')\n",
        "    report = metrics.classification_report(y_true=labels, y_pred=predicted)\n",
        "\n",
        "    return {'recall': recall, 'f1': f1, 'precision': precision, 'report': report}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1566b2a8428318c8",
      "metadata": {
        "collapsed": false,
        "id": "1566b2a8428318c8"
      },
      "source": [
        "## Model's Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ed27ccf8d0307c",
      "metadata": {
        "id": "a2ed27ccf8d0307c"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self): # TODO: define your args here\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # TODO: define you network's layers here\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # TODO: implement forward pass here\n",
        "\n",
        "        # return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "-XhOZ_qwF6Bh"
      },
      "id": "-XhOZ_qwF6Bh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d30ba6554b6c48",
      "metadata": {
        "id": "76d30ba6554b6c48"
      },
      "outputs": [],
      "source": [
        "# TODO: instantiate your model here\n",
        "# model ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57ddcb0836683ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a57ddcb0836683ec",
        "outputId": "0695a446-bb1b-49cc-8eaf-b059c477d173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ],
      "source": [
        "cnn_model_train_history = train_model( # TODO: train your model\n",
        "    ...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac375ced89f224ce",
      "metadata": {
        "id": "ac375ced89f224ce"
      },
      "outputs": [],
      "source": [
        "trend_plot_helper(\n",
        "    {\n",
        "        \"Accuracy - Epoch\": [\n",
        "            (\"Train Acc\", cnn_model_train_history[\"train_acc\"]),\n",
        "            (\"Validation Acc\", cnn_model_train_history[\"valid_acc\"]),\n",
        "        ],\n",
        "        \"Loss - Epoch\": [\n",
        "            (\"Train Loss\", cnn_model_train_history[\"train_loss\"]),\n",
        "            (\"Validation Loss\", cnn_model_train_history[\"valid_loss\"])\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a09473d5783fa70f",
      "metadata": {
        "id": "a09473d5783fa70f"
      },
      "outputs": [],
      "source": [
        "cnn_model_report = generate_confusion_matrix(\n",
        "    model=cnn_model,\n",
        "    dataset=valid_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee01e4607601dd8",
      "metadata": {
        "id": "8ee01e4607601dd8"
      },
      "outputs": [],
      "source": [
        "print(f\"Recall:    {cnn_model_report['recall']:.3f}\")\n",
        "print(f\"F1:        {cnn_model_report['f1']:.3f}\")\n",
        "print(f\"Precision: {cnn_model_report['precision']:.3f}\")\n",
        "print(cnn_model_report['report'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eY99YE-VG1C9",
        "cf946d026ed2d98e",
        "27110752c038c1d0",
        "2e129c7a31663741",
        "21730f8dd01e5b4e",
        "4b87e7e8b267a1c8",
        "bd00ab880892e646",
        "670fcd8db0e5651c"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}